<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody>
      <tr>
        <td>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td width="67%" valign="middle">
                  <p align="center">
                    <name>Tom Silver</name>
                  </p>
                  <p>Welcome to my academic website. You are probably here to see <a href="nomsy.html">pictures of my
                      dog</a>. Otherwise, read on.
                  </p>
                  <p>I am a fifth year computer science PhD student at MIT. I am advised by Leslie Kaelbling and Joshua
                    Tenenbaum and am a member of the <a href="http://lis.csail.mit.edu/">Learning and Intelligent
                      Systems group</a> and the <a href="http://cocosci.mit.edu/">Computational Cognitive Science
                      group</a>. I am grateful for support from an NSF Graduate Research Fellowship and an MIT
                    Presidential Fellowship. Previously I was a researcher at <a
                      href="https://www.vicarious.com/">Vicarious AI</a>. I received my B.A. from Harvard in computer
                    science and mathematics in 2016.
                  </p>
                  <p>Feel free to contact me at tslvr@mit.edu.
                  </p>
                  <p>[<a href="https://scholar.google.com/citations?user=CMcsygMAAAAJ">Google Scholar</a>]
                    [<a href="https://twitter.com/tomssilver">Twitter</a>]
                  </p>
                </td>
                <td width="33%">
                  <img src="images/TomSilver2.jpg">
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td width="100%" valign="middle">
                  <h1>Research</h1>
                  <p>My research is motivated by the prospect of broadly-competent intelligent robots that can respond
                    to very high-level commands like "make me a heart-healthy dinner"; learn new skills like "grind
                    fresh pepper"; and learn new concepts like "wilted spinach." Such robots would be especially
                    transformative for people who could not otherwise remain independent in their homes. Most of my work
                    is at the intersection of automated planning and machine learning: <em>learning to plan</em> and
                    <em>planning to learn</em> while making <em>efficient</em> use of limited data and time. I often use
                    techniques from <em>task and motion planning</em>, <em>program synthesis</em>, and
                    <em>neuro-symbolic machine learning</em>. Below are selected works; see <a
                      href="https://scholar.google.com/citations?user=CMcsygMAAAAJ">Google Scholar</a> for a full list.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="0" style="padding: 10px 0px 0px 20px;">
            <tbody>
              <tr>
                <td width="100%">
                  <h2>Learning Abstractions for Robotic Planning</h2>
                  <p>Abstractions can be very useful for decision making because they allow the agent to first focus on
                    the high-level aspects of a task before getting bogged down in details. We would like a robot to
                    synthesize abstractions — <em>state abstractions (predicates)</em>, <em>action abstractions
                      (skills)</em>, and <em>task abstractions (relevant objects)</em> — that are most useful for
                    planning in its specific domain.</p>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" style="padding: 20px 0px 0px 20px">
            <tbody>
              <tr>
                <td width="100%">
                  <h3 style="margin-bottom: 0px;">Learning State and Action Abstractions</h3>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="10" style="padding: 0px 0px 0px 20px;">
            <tbody>
              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/predicators_image.png" width="160" vspace="20"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/2203.09634">
                    <papertitle>Predicate invention for bilevel planning</papertitle>
                  </a>
                  <br>
                  <strong>Tom Silver*</strong>, Rohan Chitnis*, Nishanth Kumar, Willie McClinton, Tomas Lozano-Perez,
                  Leslie Kaelbling, Joshua Tenenbaum
                  <br>
                  <em>AAAI</em>, 2023. Also appeared at <em>RLDM</em>, 2022 <font color="red"><strong>(Spotlight
                      Talk)</strong></font>.
                  <br>
                  [<a href="bib/predicators.bib">BibTeX</a>]
                  [<a href="https://tinyurl.com/predicators-release">Code</a>]
                  [<a href="https://arxiv.org/pdf/2203.09634.pdf">PDF</a>]
                  <br>
                  <p></p>
                  <p>We learn neuro-symbolic and relational state and action abstractions from demonstrations. The
                    abstractions are explicitly optimized for effective and efficient bilevel planning.</p>
                </td>
              </tr>
              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/bpns_image.png" width="160" vspace="20"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/2206.10680">
                    <papertitle>Learning neuro-symbolic skills for bilevel planning</papertitle>
                  </a>
                  <br>
                  <strong>Tom Silver</strong>, Ashay Athalye, Joshua Tenenbaum, Tomas Lozano-Perez, Leslie Kaelbling
                  <br>
                  <em>Conference on Robot Learning (CoRL)</em>, 2022
                  <br>
                  [<a href="bib/bpns.bib">BibTeX</a>]
                  [<a href="https://youtu.be/PbFZP8rPuGg">Video</a>]
                  [<a href="https://tinyurl.com/skill-learning">Code</a>]
                  [<a href="https://arxiv.org/pdf/2206.10680.pdf">PDF</a>]
                  <br>
                  <p></p>
                  <p>We learn neuro-symbolic skills with goal-conditioned policies from demonstrations and symbolic
                    predicates. The learned skills can be used with bilevel task and motion planning techniques.</p>
                </td>
              </tr>

              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/gentamp_image.png" width="160" vspace="20"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/2109.11082">
                    <papertitle>Discovering state and action abstractions for generalized task and motion planning
                    </papertitle>
                  </a>
                  <br>
                  Aidan Curtis, <strong>Tom Silver</strong>, Joshua Tenenbaum, Tomas Lozano-Perez, Leslie Kaelbling
                  <br>
                  <em>AAAI</em>, 2022
                  <br>
                  [<a href="bib/gentamp.bib">BibTeX</a>]
                  [<a href="https://github.com/generalizedtamp/GeneralizedTAMP">Code</a>]
                  [<a href="https://arxiv.org/pdf/2109.11082.pdf">PDF</a>]
                  <br>
                  <p></p>
                  <p>We study generalized planning in robotic settings that involve both discrete and continuous
                    actions. We propose a method for learning state and action abstractions that leads to much faster
                    decision-making over planning from scratch.</p>
                </td>
              </tr>

              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/loft_image.png" width="160" vspace="30"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/2103.00589">
                    <papertitle>Learning symbolic operators for task and motion planning</papertitle>
                  </a>
                  <br>
                  <strong>Tom Silver*</strong>, Rohan Chitnis*, Joshua Tenenbaum, Leslie Kaelbling, Tomas Lozano-Perez
                  <br>
                  <em>IROS</em>, 2021 <font color="red"><strong>(Best Paper Award Finalist, Top 5)</strong></font>
                  <br>
                  [<a href="bib/loft.bib">BibTeX</a>]
                  [<a href="https://www.youtube.com/watch?v=iVfpX9BpBRo">Video</a>]
                  [<a href="https://git.io/JCT0g">Code</a>]
                  [<a href="https://arxiv.org/pdf/2103.00589.pdf">PDF</a>]
                  <br>
                  <p></p>
                  <p>We propose a bottom-up relational approach for learning operators for task and motion planning. Our
                    approach can be seen as a "model-based" learning approach to TAMP. We compare with several
                    model-free baselines.</p>
                </td>
              </tr>

            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" style="padding: 10px 0px 0px 20px">
            <tbody>
              <tr>
                <td width="100%">
                  <h3 style="margin-bottom: 0px;">Learning Task Abstractions</h3>
                </td>
              </tr>
            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="10" style="padding: 0px 0px 0px 20px;">

            <tbody>
              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/ploi_image.png" width="160" vspace="20"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/2009.05613">
                    <papertitle>Planning with learned object importance in large problem instances using graph neural
                      networks</papertitle>
                  </a>
                  <br>
                  <strong>Tom Silver*</strong>, Rohan Chitnis*, Aidan Curtis, Joshua Tenenbaum, Tomas Lozano-Perez,
                  Leslie Kaelbling
                  <br>
                  <em>AAAI</em>, 2021
                  <br>
                  [<a href="bib/ploi.bib">BibTeX</a>]
                  [<a href="https://www.youtube.com/watch?v=FWsVJc2fvCE">Video</a>]
                  [<a href="https://github.com/tomsilver/ploi">Code</a>]
                  [<a href="https://arxiv.org/pdf/2009.05613.pdf">PDF</a>]
                  <br>
                  <p></p>
                  <p>We propose a graph neural network architecture for predicting object importance to address the
                    challenge of planning in problems that contain many, many objects.</p>
                </td>
              </tr>

              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/camp_image.png" width="160" vspace="4"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/2007.13202">
                    <papertitle>CAMPs: Learning context-specific abstractions for efficient planning in factored MDPs
                    </papertitle>
                  </a>
                  <br>
                  Rohan Chitnis*, <strong>Tom Silver*</strong>, Beomjoon Kim, Leslie Kaelbling, Tomas Lozano-Perez
                  <br>
                  <em>Conference on Robot Learning (CoRL)</em>, 2020 <font color="red"><strong>(Plenary Talk, Top
                      20)</strong></font>
                  <br>
                  [<a href="bib/camp.bib">BibTeX</a>]
                  [<a href="https://www.youtube.com/watch?v=wTXt6djcAd4">Video</a>]
                  [<a href="https://github.com/tomsilver/camps">Code</a>]
                  [<a href="https://arxiv.org/pdf/2007.13202.pdf">PDF</a>]
                  <br>
                  <p></p>
                  <p>We observe that learning to impose constraints in factored planning problems can induce
                    context-specific abstractions that afford much more efficient planning.</p>
                </td>
              </tr>


            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" style="padding: 60px 0px 0px 20px;">
            <tbody>
              <tr>
                <td width="100%">
                  <h2>Learning Policies for Rapid Decision Making</h2>
                  <p>Planning is important when the robot is faced with difficult and unfamiliar problems. But once the
                    robot gets into the habit of solving the same kinds of problems repeatedly, its decision making
                    should become fast and "second nature." In other words, the robot should compile its planning
                    experience into a reactive policy.</p>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="10" style="padding: 0px 0px 0px 20px;">

            <tbody>
              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/llm_genplan_image.png" width="160" vspace="20"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/2305.11014">
                    <papertitle>Generalized planning in PDDL domains with pretrained large language models</papertitle>
                  </a>
                  <br>
                  <strong>Tom Silver</strong>, Soham Dan, Kavitha Srinivas, Joshua Tenenbaum, Leslie
                  Kaelbling, Michael Katz
                  <br>
                  <em>Under review</em>, 2023.
                  <br>
                  [<a href="bib/llmgenplan.bib">BibTeX</a>]
                  [<a href="https://github.com/tomsilver/llm-genplan">Code</a>]
                  [<a href="https://arxiv.org/pdf/2305.11014.pdf">PDF</a>]
                  <br>
                  <p></p>
                  <p>We use GPT-4 to synthesize Python generalized plans for PDDL domains. We also propose an automated
                    debugging scheme that dramatically improves performance over one-time prompting.</p>
                </td>
              </tr>

              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/pg3_image.png" width="160" vspace="20"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href=" http://arxiv.org/abs/2204.10420">
                    <papertitle>PG3: Policy-guided planning for generalized policy generation</papertitle>
                  </a>
                  <br>
                  Ryan Yang*, <strong>Tom Silver*</strong>, Aidan Curtis, Tomas Lozano-Perez, Leslie Kaelbling
                  <br>
                  <em>IJCAI</em>, 2022. Also appeared at <em>ICAPS PRL Workshop</em>, 2022.
                  <br>
                  [<a href="bib/pg3.bib">BibTeX</a>]
                  [<a href="https://github.com/ryangpeixu/pg3">Code</a>]
                  [<a href="https://arxiv.org/pdf/2204.10420.pdf">PDF</a>]
                  <br>
                  <p></p>
                  <p>We propose a new method for generalized policy search. The main idea is that a candidate policy
                    should be used to guide planning on training problems as a mechanism for evaluating that candidate.
                  </p>
                </td>
              </tr>


              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/tactics_image.png" width="160" vspace="30"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/1904.06317">
                    <papertitle>Few-shot Bayesian imitation learning with logical program policies.</papertitle>
                  </a>
                  <br>
                  <strong>Tom Silver</strong>, Kelsey Allen, Leslie Kaelbling, Joshua Tenenbaum
                  <br>
                  <em>AAAI</em> 2020. Also appeared at <em>RLDM</em>, 2019 and
                  ICLR <a href="http://spirl.info/">SPiRL Workshop</a>.
                  <br>
                  [<a href="bib/lpp.bib">BibTeX</a>]
                  [<a href="https://arxiv.org/pdf/1904.06317.pdf">PDF</a>]
                  [<a href="https://sites.google.com/view/plp-mit">Website</a>]
                  [<a href="https://github.com/tomsilver/policies_logic_programs">Code</a>]
                  [<a href="https://youtu.be/MJTPdEj2y_4">Video</a>]
                  <br>
                  <p></p>
                  <p>We can learn policies from five or fewer demonstrations that generalize to dramatically different
                    test task instances.</p>
                </td>
              </tr>

              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/rpl_image.png" width="160" vspace="10"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/1812.06298">
                    <papertitle>Residual policy learning</papertitle>
                  </a>
                  <br>
                  <strong>Tom Silver</strong>*, Kelsey Allen*, Joshua Tenenbaum, Leslie Kaelbling
                  <br>
                  <em>arXiv</em>, 2018
                  <br>
                  [<a href="bib/rpl.bib">BibTeX</a>]
                  [<a href="https://arxiv.org/pdf/1812.06298.pdf">PDF</a>]
                  [<a href="https://k-r-allen.github.io/residual-policy-learning/">Website</a>]
                  [<a href="https://github.com/k-r-allen/residual-policy-learning">Code</a>]
                  [<a href="https://www.youtube.com/watch?v=TbALweu6Zpc">Video</a>]
                  <br>
                  <p></p>
                  <p>We present a simple method for improving nondifferentiable policies using model-free deep
                    reinforcement learning.</p>
                </td>
              </tr>
            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="0" style="padding: 30px 0px 0px 20px">
            <tbody>
              <tr>
                <td width="100%">
                  <h2 style="margin-bottom: 0px;">Learning to Improve Decision Making through Online Exploration</h2>
                  <p>An intelligent robot should actively collect its own data, and learn from that data, so that it can
                    make better decisions in the future. If an expert is available to provide demonstrations or answer
                    questions, the robot should ask for help, but should do so judiciously. </p>
                </td>
              </tr>
            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="10" style="padding: 0px 0px 0px 20px;">

            <tbody>
              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/embodiedactive_image.png" width="160" vspace="30"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/2303.04912">
                    <papertitle>Embodied active learning of relational state abstractions for bilevel planning
                    </papertitle>
                  </a>
                  <br>
                  Amber Li, <strong>Tom Silver</strong>
                  <br>
                  <em>Conference on Lifelong Learning Agents (CoLLAs)</em>, 2023
                  <br>
                  [<a href="bib/embodiedactive.bib">BibTeX</a>]
                  [<a href="https://arxiv.org/pdf/2303.04912.pdf">PDF</a>]
                  [<a href="https://tinyurl.com/active-predicates">Code</a>]
                  <p></p>
                  <p>We consider a setting where a robotic agent must learn the meaning of predicates by querying an
                    expert about the current world state. Before generating an informative query, the robot must take
                    actions to reach an interesting world state.</p>
                </td>
              </tr>

              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/glib_image.png" width="160" vspace="0"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/2001.08299">
                    <papertitle>GLIB: Efficient exploration for relational model-based reinforcement learning via
                      goal-literal babbling</papertitle>
                  </a>
                  <br>
                  Rohan Chitnis*, <strong>Tom Silver*</strong>, Joshua Tenenbaum, Leslie Kaelbling, Tomas Lozano-Perez
                  <br>
                  <em>AAAI</em>, 2021
                  <br>
                  [<a href="bib/glib.bib">BibTeX</a>]
                  [<a href="https://www.youtube.com/watch?v=F6lmrPT6TOY">Video</a>]
                  [<a href="https://github.com/ronuchit/GLIB-AAAI-2021">Code</a>]
                  [<a href="https://arxiv.org/pdf/2001.08299.pdf">PDF</a>]
                  <br>
                  <p></p>
                  <p>We propose goal-literal babbling (GLIB), a simple and general method that addresses the problem of
                    efficient exploration for transition model learning in the relational model-based reinforcement
                    learning setting without extrinsic goals or rewards.</p>
                </td>
              </tr>

              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/pddlgym_image.png" width="160" vspace="12"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/2002.06432">
                    <papertitle>PDDLGym: Gym environments from PDDL problems</papertitle>
                  </a>
                  <br>
                  <strong>Tom Silver</strong>, Rohan Chitnis
                  <br>
                  <em>ICAPS PRL Workshop</em>, 2020
                  <br>
                  [<a href="bib/pddlgym.bib">BibTeX</a>]
                  [<a href="https://github.com/tomsilver/pddlgym">Code</a>]
                  [<a href="https://arxiv.org/pdf/2002.06432.pdf">PDF</a>]
                  <br>
                  <p></p>
                  <p>We present PDDLGym, a framework that automatically constructs OpenAI Gym environments from PDDL
                    domains and problems.</p>
                </td>
              </tr>


              <tr>
                <td width="25%">
                  <div class="one">
                    <div class="two"><img src="images/schemanet_image.png" width="160" vspace="30"></div>
                  </div>
                </td>
                <td valign="middle" width="75%">
                  <a href="https://arxiv.org/abs/1706.04317">
                    <papertitle>Schema networks: zero-shot transfer with a generative causal model of intuitive physics
                    </papertitle>
                  </a>
                  <br>
                  Ken Kansky, <strong>Tom Silver</strong>, David A. Mely, Mohamed Eldawy, Miguel Lazaro-Gredilla,
                  Xinghua Lou, Nimrod Dorfman, Szymon Sidor, Scott Phoenix, Dileep George
                  <br>
                  <em>ICML</em>, 2017
                  <br>
                  [<a href="bib/schemanetworks.bib">BibTeX</a>]
                  [<a href="https://arxiv.org/pdf/1706.04317.pdf">PDF</a>]
                  [<a href="https://www.vicarious.com/2017/08/07/general-game-playing-with-schema-networks/">Blog
                    Post</a>] [<a href="https://www.youtube.com/watch?v=QHcAlAprFxA">Video</a>]
                  [Press Coverage:
                  <a
                    href="https://techcrunch.com/2017/07/25/vicarious-gets-another-50-million-to-expand-its-research-team-and-build-smarter-robots/">TechCrunch</a>,
                  <a
                    href="https://www.wired.com/story/vicarious-schema-networks-artificial-intelligence-atari-demo/">Wired</a>,
                  <a
                    href="https://www.sciencemag.org/news/2018/05/how-researchers-are-teaching-ai-learn-child">Science</a>]
                  <p></p>
                  <p>We introduce the Schema Network, an object-oriented generative physics simulator capable of
                    disentangling multiple causes of events and reasoning backward through causes to achieve goals.</p>
                </td>
              </tr>

            </tbody>
          </table>


          <!-- <table width="100%" align="center" border="0" cellspacing="0" style="padding: 30px 0px 0px 20px">
              <tr>
                <td width="100%">
                  <h2 style="margin-bottom: 0px;">Other Projects</h2>
                </td>
              </tr>
            </table>
    
  
            <table width="100%" align="center" border="0" cellspacing="0" style="padding: 0px 0px 0px 20px;">
  
            <tr>
              <td width="25%">
                <div class="one">
                  <div class="two"><img src='images/icaps22_image.png' width="160" vspace="20"></div>
                </div>
              </td>
              <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/2109.14830">
                  <papertitle>Reinforcement learning for classical planning: viewing heuristics as dense reward generators</papertitle>
              </a>
                <br>
                Clement Gehring*, Masataro Asai*, Rohan Chitnis, <strong>Tom Silver</strong>, Leslie Kaelbling, Shirin Sohrabi, Michael Katz
                <br>
                <em>ICAPS</em>, 2022
                <br>
                [<a href="bib/icaps22.bib">BibTeX</a>]
                [<a href="https://arxiv.org/pdf/2109.14830.pdf">PDF</a>]
                <br>
                <p></p>
                <p>We learn neural logic machine value functions as residuals on classical planning heuristics in PDDL domains.</p>
              </td>
            </tr>
  
    
  
  
            <tr>
              <td width="25%">
                <div class="one">
                  <div class="two"><img src='images/tamp21_image.png' width="160" vspace="36"></div>
                </div>
              </td>
              <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/2010.01083">
                <papertitle>Integrated Task and Motion Planning</papertitle>
              </a>
                <br>
                Caelan Reed Garrett, Rohan Chitnis, Rachel Holladay, Beomjoon Kim, <strong>Tom Silver</strong>, Leslie Pack Kaelbling, Tomas Lozano-Perez
                <br>
                <em>Annual Review of Control, Robotics, and Autonomous Systems. Vol. 4</a></em>, 2021
                <br>
                [<a href="bib/tamp21.bib">BibTeX</a>]
                [<a href="https://arxiv.org/pdf/2010.01083.pdf">PDF</a>]
                <br>
                <p></p>
                <p>We define a class of TAMP problems and survey algorithms for solving them, characterizing the solution methods in terms of their strategies for solving the continuous-space subproblems and their techniques for integrating the discrete and continuous components of the search.</p>
              </td>
            </tr>
  
            <tr>
              <td width="25%">
                <div class="one">
                  <div class="two"><img src='images/sips_image.png' width="160" vspace="16"></div>
                </div>
              </td>
              <td valign="middle" width="75%">
              <a href="https://arxiv.org/abs/2006.07532">
                  <papertitle>Online Bayesian Goal Inference for Boundedly-Rational Planning Agents</papertitle>
              </a>
                <br>
                Tan Zhi-Xuan, Jordyn L. Mann, <strong>Tom Silver</strong>, Joshua Tenenbaum, Vikash K. Mansinghka
                <br>
                <em>NeurIPS</em>, 2020
                <br>
                [<a href="bib/sips.bib">BibTeX</a>]
                [<a href="https://arxiv.org/pdf/2006.07532.pdf">PDF</a>]
                <br>
                <p></p>
                <p>We present an architecture capable of inferring an agent's goals online from both optimal and non-optimal sequences of actions.</p>
              </td>
            </tr>
  
            <tr>
              <td width="25%">
                <div class="one">
                  <div class="two"><img src='images/iros20_image.png' width="160" vspace="36"></div>
                </div>
              </td>
              <td valign="middle" width="75%">
              <a href="https://joaoloula.github.io/Learning_Constraint_based_Planning_Models_From_Demonstrations.pdf">
                <papertitle>Learning constraint-based planning models from demonstrations</papertitle>
              </a>
                <br>
                Jo&atilde;o Loula, Kelsey Allen, <strong>Tom Silver</strong>, Joshua Tenenbaum
                <br>
                <em>IROS</a></em>, 2020
                <br>
                [<a href="bib/iros20.bib">BibTeX</a>]
                [<a href="https://joaoloula.github.io/Learning_Constraint_based_Planning_Models_From_Demonstrations.pdf">PDF</a>]
                <br>
                <p></p>
                <p>We present a framework for learning constraint-based task and motion planning models using gradient descent.</p>
              </td>
            </tr>
  
            <tr>
              <td width="25%">
                <div class="one">
                  <div class="two"><img src='images/genplan20_image.png' width="160" vspace="24"></div>
                </div>
              </td>
              <td valign="middle" width="75%">
              <a href="papers/genplan20_camera_ready.pdf">
                  <papertitle>Learning skill hierarchies from predicate descriptions and self-supervision</papertitle>
              </a>
                <br>
                <strong>Tom Silver*</strong>, Rohan Chitnis*, Anurag Ajay, Joshua Tenenbaum, Leslie Kaelbling
                <br>
                <em>AAAI GenPlan Workshop</em>, 2020
                <br>
                [<a href="bib/genplan20.bib">BibTeX</a>]
                [<a href="papers/genplan20_camera_ready.pdf">PDF</a>]
                <br>
                <p></p>
                <p>We learn lifted, goal-conditioned policies and use STRIPS planning with learned operator descriptions to solve a large suite of unseen test tasks.</p>
              </td>
            </tr>
  
            
            
            <tr>
              <td width="25%">
                <div class="one">
                  <div class="two"><img src='images/spare_image.png' width="160" vspace="24"></div>
                </div>
              </td>
              <td valign="middle" width="75%">
              <a href="https://openreview.net/forum?id=SJxsV2R5FQ">
                  <papertitle>Learning sparse relational transition models</papertitle>
              </a>
                <br>
                Victoria Xia, Zi Wang, Kelsey Allen, <strong>Tom Silver</strong>, Leslie Kaelbling
                <br>
                <em>ICLR</em>, 2019
                <br>
                [<a href="bib/iclr19.bib">BibTeX</a>]
                [<a href="https://openreview.net/pdf?id=SJxsV2R5FQ">PDF</a>]
                <p></p>
                <p>We present a representation for describing transition models in complex uncertain domains using relational rules.</p>
              </td>
            </tr>
  
            <tr>
              <td width="25%">
                <div class="one">
                  <div class="two"><img src='images/icml2019_image.png' width="160" vspace="20"></div>
                </div>
              </td>
              <td valign="middle" width="75%">
                <papertitle>Learning models for mode-based planning</papertitle>
                <br>
                Jo&atilde;o Loula, <strong>Tom Silver</strong>, Kelsey Allen, Joshua Tenenbaum
                <br>
                <em>ICML <a href="https://sites.google.com/view/mbrl-icml2019/home?authuser=0">MBRL Workshop</a></em>, 2019
                <br>
                <p></p>
                <p>We present a model that learns mode constraints from expert demonstrations. We show that it is data efficient, and that it learns interpretable representations that it can leverage to effectively plan in out-of-distribution environments.</p>
              </td>
            </tr>
  
            <tr>
              <td width="25%">
                <div class="one">
                  <div class="two"><img src='images/cogsci2019_image.png' width="160" vspace="1"></div>
                </div>
              </td>
              <td valign="middle" width="75%">
                <papertitle>Discovering a symbolic planning language from continuous experience</papertitle>
                <br>
                Jo&atilde;o Loula, <strong>Tom Silver</strong>, Kelsey Allen, Joshua Tenenbaum
                <br>
                <em>CogSci</em>, 2019
                <br>
                <p></p>
                <p>We present a model that starts out with a language of low-level physical constraints and, by  observing expert demonstrations, builds up a library of high-level concepts that afford planning  and action understanding.</p>
              </td>
            </tr>
  
            <tr>
              <td width="25%">
                <div class="one">
                  <div class="two"><img src='images/smc_image.gif' width="160" vspace="32"></div>
                </div>
              </td>
              <td valign="middle" width="75%">
              <a href="https://www.vicarious.com/wp-content/uploads/2018/01/AAAI18-pixelworld.pdf">
                  <papertitle>Behavior is everything &mdash; towards representing concepts with sensorimotor contingencies</papertitle>
              </a>
                <br>
                Nicholas Hay, Michael Stark, Alexander Schlegel, Carter Wendelken, Dennis Park, Eric Purdy, <strong>Tom Silver</strong>, D. Scott Phoenix, Dileep George
                <br>
                <em>AAAI</em>, 2018
                <br>
                [<a href="bib/smcs.bib">BibTeX</a>]
                [<a href="https://www.vicarious.com/wp-content/uploads/2018/01/AAAI18-pixelworld.pdf">PDF</a>]
                [<a href="https://www.vicarious.com/2018/02/07/learning-concepts-through-sensorimotor-interactions/">Blog Post</a>]
                [<a href="https://github.com/vicariousinc/pixelworld">Code</a>]
                <br>
                <p></p>
                <p>We propose an interactive, behavior-based model that represents concepts using sensorimotor contingencies grounded in an agent's experience.</p>
              </td>
            </tr>
  
  
  
            <tr>
              <td width="25%">
                <div class="one">
                  <div class="two"><img src='images/luna_image.png' width="160" vspace="40"></div>
                </div>
              </td>
              <td valign="middle" width="75%">
              <a href="https://dash.harvard.edu/handle/1/38811432">
                  <papertitle>Luna: a game-based rating system for Artificial Intelligence</papertitle>
              </a>
                <br>
                <strong>Tom Silver</strong>
                <br>
                <em>Harvard undergraduate thesis</em>, 2016
                <br>
                [<a href="https://medium.com/@tomssilver/launching-the-luna-rating-system-481a965b11d4">Blog Post</a>]
                <br>
                <p></p>
                <p>I implement a two-player game and a rating system to measure machine intelligence via crowdsourcing.</p>
              </td>
            </tr>
  
          </td>
      </tr>
    </table> -->

          <table width="100%" cellspacing="0" cellpadding="20" border="0" align="center">
            <tbody>
              <tr>
                <td>
                  <br>
                  <p align="center">
                    <font size="2">
                      Template from <a href="https://github.com/jonbarron/jonbarron_website">here.</a>
                    </font>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>




        </td>
      </tr>
    </tbody>
  </table>
</body>